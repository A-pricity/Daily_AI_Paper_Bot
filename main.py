"""
AI å‰æ²¿è®ºæ–‡æ—¥æŠ¥ç”Ÿæˆå™¨ - ä¸»ç¨‹åºå…¥å£

æ¨¡å—åŒ–æ¶æ„ï¼š
- config: é…ç½®ç®¡ç†
- sources: å¤šæ•°æ®æºè®ºæ–‡è·å–
- llm: LLM æ‘˜è¦ç”Ÿæˆ
- notification: å¾®ä¿¡æ¨é€
- utils: è¾…åŠ©å·¥å…·å‡½æ•°
"""

import datetime
import re
from typing import List, Dict

from config import Settings, SOURCES_CONFIG
from sources import ArxivSource, SpringerSource, SemanticScholarSource
from llm import LLMClient
from notification import WeChatNotifier
from utils import deduplicate_papers


class PaperBot:
    """è®ºæ–‡æ—¥æŠ¥ç”Ÿæˆæœºå™¨äºº"""

    def __init__(self):
        """åˆå§‹åŒ–æœºå™¨äºº"""
        print("=" * 50)
        print("AI å‰æ²¿è®ºæ–‡æ—¥æŠ¥ç”Ÿæˆå™¨")
        print("=" * 50)

        # åˆå§‹åŒ–ç»„ä»¶
        self.llm_client = LLMClient()
        self.notifier = WeChatNotifier()

        # åˆå§‹åŒ–æ•°æ®æº
        self.sources = []
        if SOURCES_CONFIG['arxiv']['enabled']:
            self.sources.append(ArxivSource(SOURCES_CONFIG['arxiv']))
        if SOURCES_CONFIG['springer']['enabled']:
            self.sources.append(SpringerSource(SOURCES_CONFIG['springer']))
        if SOURCES_CONFIG['semantic_scholar']['enabled']:
            self.sources.append(SemanticScholarSource(SOURCES_CONFIG['semantic_scholar']))

        print(f"\nâœ“ å·²åˆå§‹åŒ– {len(self.sources)} ä¸ªæ•°æ®æº")

    def fetch_all_papers(self) -> List[Dict]:
        """
        ä»æ‰€æœ‰å¯ç”¨çš„æ•°æ®æºè·å–è®ºæ–‡

        Returns:
            è®ºæ–‡åˆ—è¡¨
        """
        print("\nğŸ“š å¼€å§‹è·å–è®ºæ–‡æ•°æ®...")
        print("=" * 50)

        all_papers = []

        # ä»å„æ•°æ®æºè·å–è®ºæ–‡
        for source in self.sources:
            try:
                papers = source.fetch_papers()
                # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                paper_dicts = [p.to_dict() for p in papers]
                all_papers.extend(paper_dicts)
            except Exception as e:
                print(f"âš  æ•°æ®æº {source.__class__.__name__} å‡ºé”™: {e}")

        # å»é‡
        print(f"\nğŸ”„ åŸå§‹è®ºæ–‡æ•°: {len(all_papers)}")
        unique_papers = deduplicate_papers(all_papers)
        print(f"âœ“ å»é‡å: {len(unique_papers)}")

        # é™åˆ¶æ•°é‡
        papers = unique_papers[:Settings.MAX_PAPERS]
        print(f"âœ“ æœ€ç»ˆé€‰å–: {len(papers)} ç¯‡\n")

        return papers

    def generate_daily_report(self, papers: List[Dict]) -> str:
        """
        ç”Ÿæˆæ—¥æŠ¥å†…å®¹

        Args:
            papers: è®ºæ–‡åˆ—è¡¨

        Returns:
            æ—¥æŠ¥å†…å®¹
        """
        # ç»Ÿè®¡å„æ•°æ®æº
        source_stats = {}
        for paper in papers:
            source = paper.get('source', 'Unknown')
            source_stats[source] = source_stats.get(source, 0) + 1

        # æ„å»ºæŠ¥å‘Šå¤´éƒ¨
        report = f"# ğŸ“… AI å‰æ²¿è®ºæ–‡æ—¥æŠ¥ ({datetime.date.today()})\n\n"
        report += f"**ä¸»é¢˜**: å¤§è¯­è¨€æ¨¡å‹ã€æ™ºèƒ½ä½“ã€å¢å¼ºå‹LLMæ¨ç†å’Œæ¨ç†ä¼˜åŒ–\n\n"
        report += f"**æ•°æ®æº**: {', '.join(source_stats.keys())}\n\n"
        report += f"ä»Šæ—¥ä¸ºæ‚¨ç²¾é€‰ {len(papers)} ç¯‡æœ€æ–°è®ºæ–‡\n\n"

        # ç”Ÿæˆæ¯ç¯‡è®ºæ–‡çš„æ‘˜è¦
        for i, paper in enumerate(papers, 1):
            print(f"\n[è¿›åº¦] å¤„ç†ç¬¬ {i}/{len(papers)} ç¯‡è®ºæ–‡...")

            summary = self.llm_client.generate_summary(paper)

            report += f"{summary}\n"
            report += f"ğŸ”— **åŸæ–‡é“¾æ¥**: {paper['url']}\n"
            if 'source' in paper:
                report += f"ğŸ“š **æ¥æº**: {paper['source']}\n"
            report += "---\n\n"

        return report

    def save_report(self, report: str) -> None:
        """
        ä¿å­˜æ—¥æŠ¥åˆ°æ–‡ä»¶

        Args:
            report: æ—¥æŠ¥å†…å®¹
        """
        with open(Settings.REPORT_FILE, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"\nâœ… æŠ¥å‘Šå·²ä¿å­˜åˆ° {Settings.REPORT_FILE}")

    def send_wechat_notification(self, report: str) -> bool:
        """
        å‘é€å¾®ä¿¡é€šçŸ¥

        Args:
            report: æ—¥æŠ¥å†…å®¹

        Returns:
            æ˜¯å¦å‘é€æˆåŠŸ
        """
        if not Settings.WECHAT_WEBHOOK:
            print("\nâš  æœªé…ç½®ä¼ä¸šå¾®ä¿¡ Webhookï¼Œè·³è¿‡å¾®ä¿¡æ¨é€")
            return False

        print("\næ­£åœ¨æ¨é€åˆ°å¾®ä¿¡...")

        # ä¼ä¸šå¾®ä¿¡æœºå™¨äºº Markdown æ¶ˆæ¯é•¿åº¦é™åˆ¶çº¦ 4096 å­—ç¬¦
        max_length = 4000

        # è§£ææŠ¥å‘Šå†…å®¹å¹¶é‡æ–°ç»„ç»‡ä¸ºç´§å‡‘æ ¼å¼
        wechat_message = self._format_wechat_message(report)

        # å¦‚æœæ¶ˆæ¯è¶…è¿‡é•¿åº¦é™åˆ¶ï¼Œè¿›è¡Œæˆªæ–­
        if len(wechat_message) > max_length:
            print(f"âš  æ¶ˆæ¯è¿‡é•¿ ({len(wechat_message)} å­—ç¬¦)ï¼Œå°†æˆªæ–­åˆ° {max_length} å­—ç¬¦")
            wechat_message = wechat_message[:max_length] + "\n\n*å†…å®¹å·²æˆªæ–­*"

        return self.notifier.send(wechat_message)

    def _format_wechat_message(self, report: str) -> str:
        """
        å°†å®Œæ•´æŠ¥å‘Šæ ¼å¼åŒ–ä¸ºé€‚åˆä¼ä¸šå¾®ä¿¡çš„ç´§å‡‘æ¶ˆæ¯

        Args:
            report: åŸå§‹æŠ¥å‘Šå†…å®¹

        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯
        """
        lines = report.split('\n')
        result = []
        current_paper = None
        i = 0

        # è§£æå¤´éƒ¨ä¿¡æ¯
        while i < len(lines) and not lines[i].strip().startswith('##'):
            line = lines[i].strip()
            if line:
                result.append(line)
            i += 1

        # æ·»åŠ åˆ†éš”çº¿
        result.append('---')

        # è§£ææ¯ç¯‡è®ºæ–‡
        paper_count = 0
        while i < len(lines):
            line = lines[i].strip()

            # æ£€æµ‹æ–°è®ºæ–‡å¼€å§‹
            if line.startswith('## ğŸ“„ è®ºæ–‡æ ‡é¢˜ï¼š'):
                # ä¿å­˜ä¸Šä¸€ç¯‡è®ºæ–‡
                if current_paper:
                    result.append(self._format_paper_compact(current_paper))
                    result.append('---')

                # å¼€å§‹æ–°è®ºæ–‡
                current_paper = {
                    'title_zh': line.replace('## ğŸ“„ è®ºæ–‡æ ‡é¢˜ï¼š', '').strip(),
                    'title_en': '',
                    'author': '',
                    'institution': '',
                    'sections': {}
                }
                paper_count += 1

            elif line.startswith('**åŸæ ‡é¢˜**ï¼š'):
                current_paper['title_en'] = line.replace('**åŸæ ‡é¢˜**ï¼š', '').strip()
            elif line.startswith('**ç¬¬ä¸€ä½œè€…**ï¼š'):
                author_info = line.replace('**ç¬¬ä¸€ä½œè€…**ï¼š', '').strip()
                parts = author_info.split('|')
                current_paper['author'] = parts[0].strip()
                current_paper['institution'] = parts[1].strip() if len(parts) > 1 else 'æœªçŸ¥'
            elif line.startswith('### ğŸ¯ æ ¸å¿ƒæ‘˜è¦'):
                current_paper['sections']['summary'] = []
            elif line.startswith('### ğŸ’¡ æ ¸å¿ƒåˆ›æ–°ç‚¹ä¸è´¡çŒ®'):
                current_paper['sections']['innovations'] = []
            elif line.startswith('### ğŸ§ ç®€è¯„ä¸å¯ç¤º'):
                current_paper['sections']['comment'] = []
            elif line.startswith('ğŸ”— **åŸæ–‡é“¾æ¥**ï¼š'):
                current_paper['url'] = line.replace('ğŸ”— **åŸæ–‡é“¾æ¥**ï¼š', '').strip()
            elif line.startswith('ğŸ“š **æ¥æº**ï¼š'):
                current_paper['source'] = line.replace('ğŸ“š **æ¥æº**ï¼š', '').strip()
            elif line.startswith('*') and current_paper and 'innovations' in current_paper['sections']:
                # åˆ›æ–°ç‚¹åˆ—è¡¨
                innovation = line.replace('*', '').strip()
                if innovation:
                    current_paper['sections']['innovations'].append(innovation)
            elif line and current_paper and not line.startswith('#') and not line.startswith('**'):
                # æ™®é€šå†…å®¹
                if 'summary' in current_paper['sections']:
                    current_paper['sections']['summary'].append(line)
                elif 'comment' in current_paper['sections']:
                    current_paper['sections']['comment'].append(line)

            i += 1

        # æ·»åŠ æœ€åä¸€ç¯‡è®ºæ–‡
        if current_paper:
            result.append(self._format_paper_compact(current_paper))

        # æ·»åŠ åº•éƒ¨ä¿¡æ¯ï¼ˆå¼•ç”¨å—æ ·å¼ï¼‰
        result.append('')
        result.append('---')
        result.append(f"> ğŸ“… {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')} | ğŸ“Š å…±**{paper_count}**ç¯‡")

        return '\n'.join(result)

    def _format_paper_compact(self, paper: dict) -> str:
        """
        æ ¼å¼åŒ–å•ç¯‡è®ºæ–‡ä¸ºç´§å‡‘å¸ƒå±€

        Args:
            paper: è®ºæ–‡å­—å…¸

        Returns:
            æ ¼å¼åŒ–åçš„è®ºæ–‡æ–‡æœ¬
        """
        parts = []

        # æ ‡é¢˜è¡Œï¼ˆåŠ ç²—ï¼Œé‡ç‚¹çªå‡ºï¼‰
        title_line = f"ğŸ“Œ **{paper['title_zh']}**"
        parts.append(title_line)

        # è‹±æ–‡æ ‡é¢˜ï¼ˆæ¬¡è¦ä¿¡æ¯ï¼Œæ™®é€šæ–‡æœ¬ï¼‰
        if paper['title_en']:
            parts.append(f"<font color=\"info\">{paper['title_en']}</font>")

        # ä½œè€…å’Œä¿¡æ¯è¡Œï¼ˆç´§å‡‘æ’åˆ—ï¼‰
        info_line = f"> ğŸ‘¤ {paper['author']}"
        if paper.get('source'):
            info_line += f" | ğŸ“š {paper['source']}"
        parts.append(info_line)

        # æ ¸å¿ƒæ‘˜è¦ï¼ˆå•è¡Œç´§å‡‘ï¼‰
        if 'summary' in paper['sections'] and paper['sections']['summary']:
            summary_text = ' '.join(paper['sections']['summary'])
            # é™åˆ¶æ‘˜è¦é•¿åº¦ï¼Œé¿å…è¿‡é•¿
            if len(summary_text) > 150:
                summary_text = summary_text[:147] + '...'
            parts.append(f"ğŸ’¡ {summary_text}")

        # åˆ›æ–°ç‚¹ï¼ˆä½¿ç”¨ç®€æ´ç¬¦å·åˆ—è¡¨ï¼‰
        if 'innovations' in paper['sections'] and paper['sections']['innovations']:
            parts.append("> **æ ¸å¿ƒåˆ›æ–°**")
            for innovation in paper['sections']['innovations'][:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                # ç®€åŒ–åˆ›æ–°ç‚¹æ–‡æœ¬
                if len(innovation) > 80:
                    innovation = innovation[:77] + '...'
                parts.append(f"> â€¢ {innovation}")

        # ç®€è¯„ï¼ˆå•è¡Œé«˜äº®ï¼‰
        if 'comment' in paper['sections'] and paper['sections']['comment']:
            comment_text = ' '.join(paper['sections']['comment'])
            parts.append(f"ğŸ“ **ç®€è¯„**ï¼š{comment_text}")

        # åŸæ–‡é“¾æ¥ï¼ˆå¯ç‚¹å‡»ï¼Œä½¿ç”¨å¼•ç”¨å—æ ·å¼çªå‡ºï¼‰
        if 'url' in paper and paper['url']:
            parts.append(f"> ğŸ”— [ğŸ“– é˜…è¯»åŸæ–‡]({paper['url']})")

        return '\n'.join(parts)

    def run(self):
        """
        è¿è¡Œå®Œæ•´çš„æ—¥æŠ¥ç”Ÿæˆæµç¨‹
        """
        try:
            # 1. è·å–è®ºæ–‡
            papers = self.fetch_all_papers()

            if not papers:
                print("\nâš  æœªèƒ½è·å–åˆ°ä»»ä½•è®ºæ–‡ï¼Œè¯·ç¨åé‡è¯•")
                return

            # 2. ç”Ÿæˆæ—¥æŠ¥
            report = self.generate_daily_report(papers)

            # 3. è¾“å‡ºç»“æœ
            print("\n" + "=" * 20 + " ç”Ÿæˆç»“æœ " + "=" * 20 + "\n")
            print(report)

            # 4. ä¿å­˜æŠ¥å‘Š
            self.save_report(report)

            # 5. æ¨é€åˆ°å¾®ä¿¡
            self.send_wechat_notification(report)

        finally:
            # æ¸…ç†èµ„æº
            self.llm_client.close()


def main():
    """ä¸»å‡½æ•°"""
    bot = PaperBot()
    bot.run()


if __name__ == "__main__":
    main()
